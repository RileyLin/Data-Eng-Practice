https://www.1point3acres.com/bbs/thread-1089339-1-1.html

vo uber reel netflix

1. uber/doordash + DAU + Photo Upload
2. Dropbox + Newsfeed + Messenger

https://www.1point3acres.com/bbs/thread-1117388-1-1.html

BQï¼š
å¯¹DEçš„äº†è§£ï¼Œå’ŒSDEï¼ŒDSçš„åŒºåˆ«
å¦‚ä½•priority taskï¼Œå¦‚ä½•å¤„ç†conflict
data driven result å¯¹business processçš„impact
åŸºæœ¬ä¸‹é¢è¿™ä¸ªå¸–å­éƒ½åŒ…æ‹¬äº†ï¼Œä½†ä¼šæœ‰ä¸€äº›followup å¦‚æœsignalæ²¡æœ‰æ”¶é›†åˆ°ã€‚
ğŸ”—Â [www.1point3acres.com](http://www.1point3acres.com/)
ç¬¬ä¸€è½® ride sharingÂ 
å¦‚ä½•track carpoolçš„performance çš„metricsï¼Œå¦‚ä½•slice and dice dimensions
data modeléœ€è¦è€ƒè™‘fact tableå¯ä»¥åŒæ—¶æœ‰carpoolå’Œregular rides
sql ä¼šæä¾›å‡ ä¸ªè¡¨å’Œsample dataï¼Œè®¡ç®—carpoolå æ¯”
pythonæ˜¯ç±»ä¼¼meeting roomï¼Œé—®æ˜¯ä¸æ˜¯æ‰€æœ‰ride booking [{start time, end time, number_passenger}]éƒ½èƒ½complete
ç¬¬äºŒè½® short video
åŒæ ·ä»€ä¹ˆæ ·çš„metrics track performanceï¼Œæœ‰é—®é€‰ä¸€ä¸ªmetricç”»æˆä»€ä¹ˆæ ·çš„å›¾
Data model focus on engagementæœ‰è¿½é—®å¦‚ä½•æ”¹modelå¯ä»¥æ‰¾åˆ°æ˜¯ä»å“ªå„¿shareåˆ°ï¼Œæˆ‘ç»™çš„æ˜¯åŠ ä¸€ä¸ªshared_by ç”¨engagement_id
Sql åŒä¸€å¤©æœ‰likesä½†æ˜¯æ²¡æœ‰commentsçš„postï¼Œç”¨çš„æ˜¯not inã€‚åŸºæœ¬éƒ½æ˜¯group by caseï¼Œå°½é‡å†™ä¸€ä¸ªselectï¼Œå‡å°‘ç”¨cte
Python å’Œä¸‹é¢å¸–å­çš„å¾ˆç±»ä¼¼ï¼Œéœ€è¦ç”¨bufferï¼Œç®—total engagement ç„¶åprintï¼Œæœ‰ä¸€ä¸ªæ¡ä»¶æ˜¯å¦‚æœæ˜¯internal testçš„è¯ï¼Œè€ƒè™‘buffer ä½†ä¸è€ƒè™‘è®¡ç®—
ğŸ”—Â [www.1point3acres.com](http://www.1point3acres.com/)
ç¬¬ä¸‰è½® streaming platform
é—®å“ªäº›engagement typeï¼Œå’Œå“ªäº›metricsï¼Œä¼šè¿½é—®è¿˜æœ‰æ²¡æœ‰å…¶ä»–å¯ä»¥measureçš„ï¼Œä»platformï¼Œuserï¼Œvideoåˆ†å¼€è®¨è®º
designä¸€ä¸ªdata modelå¯ä»¥ç”¨æ¥å†™ä¸Šé¢æ‰€æœ‰çš„metricsã€‚ç»†èŠ‚é—®åˆ°å¦‚ä½•ç®—duration(end time - start time - pause time)ï¼Œtradeoffæ˜¯å¦è¦åŠ multiple row when consider pauseï¼Œ å¦‚ä½•ç®—is_complete.
sqlè€ƒçš„æ˜¯batch processï¼Œå¦‚ä½•update cumulative snapshotï¼Œå…ˆç®—todayçš„ï¼Œç„¶åå’Œsnapshotè¡¨è¿›è¡Œfull out joinï¼Œæ³¨æ„coalesceç»†èŠ‚
Python è€ƒçš„æ˜¯list of dicts ç”µå½±ï¼Œåˆ†ç±»ï¼Œè¯„åˆ†ï¼Œè¾“å‡ºåˆ†ç±»å’Œå¹³å‡åˆ†ï¼Œæˆ‘ç”¨çš„æ˜¯listç„¶åç®—å¹³å‡ï¼Œfollowupé—®é¢˜æ˜¯å¦‚æœæ•°æ®é‡å¾ˆå¤§å¦‚ä½•ä¼˜åŒ–ï¼Œç»“è®ºå¯ä»¥ç”¨dictå­˜å‚¨æ€»åˆ†å’Œcnt

Pythonï¼š
ç»™ä½ ä¸€ä¸ªnumberï¼Œreturn oddç»„æˆçš„æœ€å°numberã€‚1234-->13 ï¼ˆedge caseï¼šnegativeï¼ˆ-23ï¼‰ï¼Œå¶æ•°ï¼ˆ24ï¼Œ0--ã€‹ noneï¼‰ï¼‰
most frequency comment of book store (æ³¨ï¼šremove duplicatesï¼‰dic1 = {'nyc': ['perfect', 'perfect', 'briliant', 'love it!'], 'london':['gorgerous'ï¼Œ'briliant'], 'berlin':['awful']} --- resultï¼šbriliant
æ±‚è¿ç»­ä¸¤å¹´æœ€å¤šçš„class number courses = [
Â  Â  ('chemistry', 4, 2010, 2014),
Â  Â  ('math', 2, 2008, 2012)
Â  Â  ]--ã€‹resï¼š12
SQLï¼š
book transaction customer author
total books and unique customer per payment
é¡¾å®¢å¯ä»¥inviteå…¶ä»–é¡¾å®¢ï¼Œæ‰¾top 5 é‚€è¯·åˆ«çš„é¡¾å®¢çš„average payment per book --ã€‹ä¸æ˜¯avgï¼ˆpaymentï¼‰æ˜¯sum(payment)/sum(book_count) --> I struggle a bit.
å…¨éƒ¨authorçš„æ•°é‡ï¼Œauthorçš„urlç¬¦åˆæŸä¸ªpatternçš„æ¯”ä¾‹ï¼Œæ²¡æœ‰å–å‡ºå»è¿‡ä¹¦çš„authorçš„æ¯”ä¾‹ã€‚
æ€»ä½“ç®€å•ï¼Œä½†æ˜¯æˆ‘çš„é¢è¯•å®˜æ¬§æ´²å£éŸ³è´¼é‡ï¼Œ10ä¸ªè¯æˆ‘å°±èƒ½å¬æ‡‚2ï¼Œ3ä¸ªï¼Œä¸”æ°”è´¨æŠ½è±¡ï¼Œéƒ½æ˜¯é ç€é¢ç»è¿‡çš„ï¼Œæ‰€ä»¥ä¸€å®šè¦æŠŠé¢ç»é—­ç€çœ¼å†™å‡ºæ¥çš„ç¨‹åº¦ã€‚ä½†æ˜¯åˆå¾—æœ‰æ€è€ƒçš„è¿‡ç¨‹ã€‚

Python:
Smallest Odd : Create the smallest odd number from an integer
Most Frequent Theme: From a dictionary of book themes, Find the most common theme
Consecutive Year Classes: Given courses. Determine the maximum number of classes held in two consecutive years.
Bookshelf Fit: Given two list books and shelve, check if all books can fit into the shelves.
Friendship Matrix: Calculate how many people see a post after N reposts based on a friendship matrix.
SQL:
What percentage of products are both low-fat and recyclable?
What are the top five single-channel media types based on promotional spending?
For sales with valid promotions, what percentage of transactions occur on the first or last day of the campaign?
Show total units sold for each product family and the ratio of promoted to non-promoted sales, sorted by total units sold.

Rice please :)

- Data Modeling
oÂ Version 01 - Ride Sharing Company (Uber/Lyft)
ï‚§Â 15-20 mins product sense discussion:
e.g. å¦‚ä½•æ‰©å¤§å¸‚åœºå æœ‰ç‡/How to do mkt expansion
ï‚§Â 20-30 mins data modeling discussion â€“ fact table(s) & dimension tables shall be able to relevant to the product sense
ï‚§Â 5-10 mins on SQL query â€“ 1-2 queries:
e.g. è®¡ç®—åªç”¨è¿™ä¸ªappå»æœºåœºçš„äºº
oÂ Version 02 - Cloud File Storage Company (Dropbox/Google Drive)
ï‚§Â 15-20 mins product sense discussion:
e.g. How to evaluate whether the product is success (name some classical metrics and start the discussion)
ï‚§Â 20-30 mins data modeling discussion â€“ fact table(s) & dimension tables shall be able to relevant to the product sense
â€¢Â æœ‰çš„äººè¢«è¿½é—®åˆ°å¦‚æœè¿™ä¸ªfileæ˜¯share among multiple peopleçš„åº”è¯¥å¦‚ä½•è€ƒè™‘å»ºè¡¨ (æˆ‘è§‰å¾—å¯ä»¥å»ºä¸¤ä¸ªfact tables â€“ ä¸€ä¸ªæ˜¯ä¸“é—¨è®°å½•upload/download å¦ä¸€ä¸ªæ˜¯ä¸“é—¨è®°å½•shared assets)
â€¢Â æœ‰çš„äººè¢«è¿½é—®å¦‚ä½•è®°å½•file ownership transfer â€“ æˆ‘è§‰å¾—é—®é¢˜è¿˜æ˜¯ä¸Šé¢çš„é‚£ä¸ªå…³äºshare activityçš„é—®é¢˜
ï‚§Â 5-10 mins on SQL query â€“ 1-2 queries:
e.g. æ‰¾å‡ºåªä¸Šä¼ ç…§ç‰‡çš„äºº|Find one how many files (storage assets) have multiple owners
-Â Tech 01
oÂ Version 01 â€“ DAU/MAU (è¿™ä¸€è½®çš„case studyæ™®éå°±æ˜¯å›´ç»•DAU/MAUå±•å¼€çš„ ä¹Ÿæ²¡æœ‰discloseå¤ªå¤šå…·ä½“çš„å…¬å¸èƒŒæ™¯)
ï‚§Â Product sense éƒ¨åˆ†æ™®éè¢«é—®åˆ°çš„æ˜¯å¦‚æœDAU/MAUçªç„¶dropäº†å¾ˆå¤š åˆ†æä¸€ä¸‹å¯èƒ½ä¼šæ˜¯ä»€ä¹ˆåŸå› 
ï‚§Â SQL â€“ ä¼šæä¾›table çš„schema ä½†æ˜¯ä¸ä¼šç»™å®é™…çš„æ•°æ® ç­‰äºè¯´æ˜¯â€å¿™å†™â€ â€“ æ„æ€æ˜¯å†™å¥½äº†ä¹Ÿä¸ç”¨run ä½†æ˜¯åŸºæœ¬ä¸Šé¢è¯•å®˜è‚¯å®šçŸ¥é“ä»€ä¹ˆæ˜¯å¯¹çš„ä»€ä¹ˆæ˜¯é”™çš„
e.g.:
â€¢Â æ•°æ®åŒ…å«Nå¤©çš„ç™»å½•æƒ…å†µ â€“ è¦æ±‚è®¡ç®—æ‰‹æœºç™»å½•çš„ç”¨æˆ·å’Œæ‰€æœ‰ç”¨æˆ·çš„æ•°é‡(AU/N by Phone and AU/N)
â€¢Â Think about how to design a series of ETL process â€“ how to capture new users/ retained users/ churn users
â€¢Â Calc DAU by different categories (æˆ‘ä¼°è®¡æ˜¯DAU group by platforms/devices)
oÂ Version 02 â€“ News Feed
ï‚§Â Product sense â€“ how to evaluate whether users have viewed a post â€“ éœ€è¦ä¸€äº›è®¨è®º â€“ æ€ä¹ˆåˆ¤æ–­ç”¨æˆ·æ˜¯å¦æœ‰æ•ˆé˜…è¯»äº†ä¸€ä¸ªpostçš„å†…å®¹ (æœ€åæœ‰çš„ä¼šè¢«driveåˆ°å¯ä»¥è®¨è®ºæ‰€è°“çš„ å å±æ¯” â€“ å¦‚æœä¸€ä¸ªpost å å±æ¯”è¾¾åˆ°äº†x% threshold, é‚£ä¹ˆå°±æ˜¯ç®—ä½œæœ‰æ•ˆé˜…è¯»)
ï‚§Â SQL & Python
â€¢Â åˆ†åˆ«ç”¨SQLå’ŒPythonæ¥ç®—æ¯ä¸€ä¸ªsessioné‡Œé¢çš„å¯¹åº”çš„postçš„æœ‰æ•ˆé˜…è¯»çš„æ¬¡æ•°
æœ‰äº›ç»†èŠ‚çš„ä¸œè¥¿éœ€è¦ç¡®è®¤ â€“ å¦‚æœä¸€ä¸ªpostä¸‹é¢çš„æœ‰logæ˜¾ç¤ºåŒä¸€ä¸ªsession_idå¤šæ¬¡- å¯èƒ½è¡¨æ˜è¿™ä¸ªpostè¢«å¤šæ¬¡é˜…è¯»äº† é‚£ä¹ˆå¯ä»¥è€ƒè™‘å–ç¬¬ä¸€æ¬¡çš„ä¸ºå‡† æˆ–è€…å¯ä»¥è€ƒè™‘å–å¹³å‡å€¼
å…³äºschema æœ‰å¥½å‡ ä¸ªç‰ˆæœ¬ ä¸è¿‡å¯èƒ½å¤§å·®ä¸å·®
(è¡¨å¤§æ¦‚æ˜¯session_id, post_id, start_timestamp, end_timestamp, read_percent)
(Table schema â€“ session id, post id, time_stamp, event_type, percentage å…¶ä¸­event typeæœ‰start time å’Œ end time) å®é™…ä¸Šè¿™ä¸¤ä¸ªè¡¨æ˜¯å·®ä¸å¤šçš„
[è¿™ä¸ªè€Œæ„Ÿè§‰æ˜¯æ¯”è¾ƒå¯ä¿¡çš„: Sql-æ±‚å‡ºè¿™ä¸ªsessionä¸­çš„postï¼ˆæ¯ä¸ªpostéƒ½ä¼šå¯¹åº”å¥½å‡ æ¡start å’Œ end timeï¼‰æ˜¯ä¸æ˜¯æœ‰æ•ˆé˜…è¯» ï¼ˆthreshold æ˜¯5ç§’å’Œ80%å±å æ¯”éƒ½å±äºæœ‰æ•ˆé˜…è¯»ï¼‰- è¿™é¢˜æ˜¯éœ€è¦é€æ¡post evaluateï¼Œå¦‚æœå…¶ä¸­ä¸€æ¡æ˜¯æœ‰æ•ˆé˜…è¯»å°±ç®—æ˜¯æœ‰æ•ˆé˜…è¯»ã€‚è¿™ä¸ªsqlçš„é‡ç‚¹è€ƒå¯Ÿçš„æ˜¯æ€ä¹ˆæŠŠstart time å’Œ end time alignåˆ°ä¸€èµ·ï¼Œè¿™ä¸ªå†™å‡ºæ¥äº†ï¼Œåé¢éƒ½ç®€å•äº†]
(è¦æŠŠä¸Šé¢çš„è¡¨çš„timestampå˜æˆstart and end timestamp alignåˆ°ä¸€èµ·window functionåº”è¯¥æ˜¯æ¯”è¾ƒç›´è§‚çš„è§£æ³• å¦‚æœæ•°æ®æ¯”è¾ƒå¤§å¯èƒ½åªèƒ½é€šè¿‡joinæ¥è§£ ä½†æ˜¯å†™èµ·æ¥ä¼°è®¡ä¼šéº»çƒ¦ç‚¹ è¿™ä¸¤å¤©æˆ‘ä¼šçœ‹çœ‹æœ‰æ²¡æœ‰æ›´åˆé€‚çš„è§£æ³•)
â€¢Â Pythonå°±æ˜¯ä¼ªstreaming ä¸Šé¢SQLçš„å†…å®¹ ç„¶åæ¯ä¸ªsession_idä¼šæœ‰ä¸ªå¯¹åº”çš„session end signal
oÂ (æ„Ÿè§‰å°±æ˜¯æŒ‰ç…§session -> post â€“ validate_whther_in_threshold() -> update dictionary)
-Â Tech 02
oÂ Version 01- Photo Upload (æœ‰ç‚¹åƒInstagram)
ï‚§Â Product sense æ™®éååº”æ˜¯è®¨è®ºç…§ç‰‡ä¸Šä¼ æµç¨‹çš„process time
ï‚§Â SQL & Python:
â€¢Â SQL â€“ è®¡ç®—average time taken
â€¢Â Python coding â€“ è·ŸSQLæ˜¯ä¸€æ ·çš„ ä½†æ˜¯è¿™é‡Œæ˜¯è¦æ±‚å®ç°ä¼ªstreaming process â€“ ç»™ä¸€ä¸ªlog file â€“ process data line by line â€“ è®¡ç®—metrics â€“ average time taken
ï‚§Â Dashboard â€“ data visualization â€“ åŸºæœ¬ä¸Šå°±æ˜¯ç®€å•ä»‹ç»ä¸€äº›å‡†å¤‡æ€ä¹ˆå¯è§†åŒ–æ•°æ® â€“ è¯´æ˜ç™½æ¨ªè½´çºµè½´ä»¥åŠéœ€è¦visualizeçš„metricså³å¯
oÂ Version 02 â€“ FB Messenger
ï‚§Â product sense â€“ DAU/MAU â€“ å‘ç°DAU/MAU äººæ•°ä¸‹é™äº† å¯èƒ½ä¼šæœ‰å“ªäº›å› ç´ å¯¼è‡´çš„
ï‚§Â SQL and Python
â€¢Â SQL: ç»™ä¸€ä¸ªlogè¡¨ï¼Œæ±‚æ¯ä¸ªç”¨æˆ·åœ¨ä¸€å¤©é‡Œsign inè¿‡å‡ æ¬¡ï¼Œå‘äº†å¤šå°‘æ¡messageï¼Œfirst sign in dateï¼Œä»first sign in dateå¼€å§‹ä¸€å…±å‘è¿‡å¤šå°‘æ¡messageï¼Œä»Šå¤©æ˜¯ä¸æ˜¯active
(logå¥½åƒæœ‰user_id,date,send_on_ios,send_on_android)
â€¢Â Python: ç»™å‡ ä¸ªè¡¨ï¼Œç”¨pythonå†™å‡ºSQL statementsæ¯å¤©æ›´æ–°è¿™å‡ ä¸ªè¡¨
(ç»™è¡¨Aï¼Œè¡¨Bï¼Œè¡¨C è¡¨Cæ˜¯SELECT col1, col2 FROM A WHERE condition1 UNION ALL SELECT col3, col4 FROM B WHERE condition2 â€“ æ„Ÿè§‰æ˜¯ç»™äº†table ç„¶åç”¨python form SQL and insert into DB â€“ æ³¨æ„SQL injection)
(pythonçš„è¡¨å’Œlogå·®ä¸å¤šï¼Œå°±æ˜¯log by different metricsï¼Œå’Œdeviceï¼Œplatformï¼Œlocationç›¸å…³çš„data)
(æ‰€æœ‰çš„pythoné¢˜éƒ½ä¸éœ€è¦ç”¨åˆ°pandasï¼Œç®€å•ç‚¹è¯´å°±æ˜¯ç»™ä½ å‡ ä¸ªsqlè¡¨ä½ ç”¨pythonå†™ä¸€ä¸ªstringï¼Œstringçš„å†…å®¹æ˜¯â€insert into tableâ€¦â€¦â€)

Overview

1. ETL Interview 1: Real-time stream system (1 hr)
2. Data modelingÂ (1 hr)
3. ETL Interview 2: Batch system
4. Behavioral and ownership
All the technical ETL design, assume big data context
Main qualities Interviewers look for
Code needs to be written but it will not get tested throughout the interview
5. Python
6. SQL (Postgres)
7. Product sense
8. Data modeling
9. ETL
10. Data visualization (more on data presentation --> will appear in stream system ETL question)
Interview 1: ETL in Real time stream systemÂ (Photo upload stream process)
Focus on designing important metrics and E2E ETL process
Q1: (a product sense question) What metrics would you use to evaluate if a feature in the photo upload application is effective or not? What data would you collect? --> Photo upload APP?
Q2: On a high level, design the schema/columns for data modeling for both the source data and the target (output) data.
Q3: The schema of the table will be provided. A set of SQL/ python questions will be asked to answer some questions. --> It will be mainly focused on how to build ETL from source to target and transforming the data
11. Given the schema :
session_id Action timestamp
1 login 2021-11-29:00:02:01
1 click on post 2021-11-29:01:03:03
2 upload photos 2021-11-29:01:12:01
3 tag friends 2021-11-29:02:38:15
3 tag friends 2021-11-29:03:02:01
Find the average time taken between each steps/actions above. For duplicate actions (upload photo again, use the first upload photo time)
SELECT * , DATEDIFF(minutes, lag(timestamp) over (PARTITION BY user_id order by timestamp), timestamp) as inactivity_time
FROM events
12. Code question: same as above sql question, but input data like below [session_id, action/step_id, start_ts].
Table for login session_id Aï¼š
starttimeï¼š10:00 ï¼Œ upload photo
Start time: 10:04, tag friends on photos
Start time: 10:05, upload photo
Start time: 10:07, add messages
Start time: 10: 09, post photos (å®Œæˆäº†ï¼‰
session_ID B ï¼ˆå¦å¤–ä¸€ä¸ªäººï¼‰ï¼Œåšç±»ä¼¼çš„actionsã€‚å¹³å‡æ¯ä¸ªaction å¤šé•¿ï¼Ÿ
Compute and update the running new average time spent on each step for every new stream of data coming into the system, assuming infinite amount of memory space
Interview 2: Data modeling (Doordash/Uber --> ride share related product)
Key design guidelines:
â€¢ Scalability
â€¢ Maintainability
â€¢ Normalization/Denormalization
â€¢ Performance
Q1: (a product sense question related to the product)
Q2: Create your own data mart, the data dimension tables to analyze the product (Star schema is highly preferred)
Q3: Query based on the schema you've created previously to find out some metrics
1.Â Calculate all the drivers who departed or reached to the airport as the destination
13. Calculate all the customers who only departed or reached to the airport as the destination. The customers who have been to other destinations don't count
14. Discuss the parts in the table design that could have been improved
Interview 3: ETL in Batch system (Related to Meta quarterly results)
Question 1: a product sense question related to DAU, MAU
Question 2: Query to find the status/count/number of different metrics given a table with new users, retention users and timestamps in it
15. Find the daily new user: ğŸ”—Â [leetcode.com](http://leetcode.com/)
16. SQL question. Given table: user_id, last_login_time, prev_login_before_last_loginÂ a. Find: yesterday's DAU, last 7 days, last 28 daysÂ b. Find continuous user, returning user and churned users
17. Users have more than one devices, last 7 days login (1 = login with that device; 0 means didn't login with that device)
details = {'iPhone':[0, 1,0,1,0,1,0]Â ,'Android':[1, 0,0,0,0,0,1]Â ,'Web':[0, 0,1,0,0,0,0]}
rollups= {'overall':['iphone', 'Android', 'Web']Â ,'Mobile':['iPhone', 'Android']}
Question: find last 7 days for overall , mobile, etc
Return:
{ â€œoverallâ€ : [1,1,1,0,1,1,1]Â â€œMobileâ€:Â [1, 0,0,0,0,0,1]
Interview 4: Behavioral (Follow the STAR framework)
18. What draws you to Meta DE?
19. What is DE?
20. Projects you've worked on --> try to relate the experience to the FB products
21. Leadership questionsÂ a. Describe a time when you complete a project from end to endÂ b. What have you done in a cross functional, collaborative environmentÂ c. What is the impact of your projects?Â d. What trade offs did you have to makeÂ e. What characteristics and attributes do you think is important as a leader
22. Questions about autonomy/ prioritization
23. Describe a situation where you influenced/or being influenced by others using data
24. How do you handle conflict?
25. How do you plan to succeed in FB in the first year

SQL: ä¹¦åº—

1. é”€é‡å’Œæ•°é‡by payment type
2. é¡¾å®¢å¯ä»¥inviteå…¶ä»–é¡¾å®¢ï¼Œæ‰¾top 3 é‚€è¯·åˆ«çš„é¡¾å®¢çš„average paymentã€‚
3. å…¨éƒ¨authorçš„æ•°é‡ï¼Œauthorçš„urlç¬¦åˆæŸä¸ªpatternçš„æ¯”ä¾‹ï¼Œæ²¡æœ‰å–å‡ºå»è¿‡ä¹¦çš„authorçš„æ¯”ä¾‹ã€‚
Python:
4. æ‰¾ä¸€ä¸ªintä¸­å¯ä»¥ç”¨å¥‡æ•°ç»„æˆçš„æœ€å°çš„intã€‚
5. ç»™ä¸€ä¸ªä¹¦åº—çš„dictionaryï¼Œæ‰¾åˆ°æœ€å¤šçš„è¯„è®ºã€‚
6. ç»å…¸å¼€ä¼šé¢˜ã€‚æ‰¾åˆ°è¿ç»­ä¸¤å±Šå‚åŠ æœ€å¤šçš„äººã€‚
7. ä¹¦çš„åšåº¦å’Œä¹¦æ¶åšåº¦çš„fit

VO
ä»¥ä¸‹å†…å®¹éœ€è¦ç§¯åˆ†é«˜äº 188 æ‚¨å·²ç»å¯ä»¥æµè§ˆ
å› ä¸ºæˆ‘ä¹‹å‰é¢è¿‡ä¸€æ¬¡è¿™ä¸ªèŒä½äº†ï¼Œæ‰€ä»¥æˆ‘çš„é¢˜ç›®å’Œå¸¸è§çš„ä¸å¤ªä¸€æ ·ï¼Œä½†æ˜¯æœ¬è´¨éƒ½å·®ä¸å¤š
1st ETL
FB messenger
Product sense: å‘ç°sign inçš„äººæ•°çªç„¶ä¸‹é™ï¼Œé—®å¯èƒ½æœ‰å“ªäº›åŸå› 
SQL: ç»™ä¸€ä¸ªlogè¡¨ï¼Œæ±‚æ¯ä¸ªç”¨æˆ·åœ¨ä¸€å¤©é‡Œsign inè¿‡å‡ æ¬¡ï¼Œå‘äº†å¤šå°‘æ¡messageï¼Œfirst sign in dateï¼Œä»first sign in dateå¼€å§‹ä¸€å…±å‘è¿‡å¤šå°‘æ¡messageï¼Œä»Šå¤©æ˜¯ä¸æ˜¯active
Python: ç»™å‡ ä¸ªè¡¨ï¼Œç”¨pythonå†™å‡ºSQL statementsæ¯å¤©æ›´æ–°è¿™å‡ ä¸ªè¡¨
2nd ETL
FB news feed
Product sense: æ€ä¹ˆåˆ¤æ–­ç”¨æˆ·æ˜¯ä¸æ˜¯æœ‰æ•ˆé˜…è¯»äº†ä¸€ä¸ªpost
SQL: ç»™ä¸€ä¸ªlogè¡¨ï¼Œæ±‚æ¯ä¸ªsessioné‡Œçš„æ¯ä¸ªpostæœ‰å‡ ä¸ªæœ‰æ•ˆé˜…è¯»
Python: æŠŠSQLçš„é—®é¢˜ç”¨pythonå†™ä¸€é
Data Model
FB box (ç±»ä¼¼äºdropbox)
Product senseï¼š æ€ä¹ˆåˆ¤æ–­äº§å“æ˜¯å¦æˆåŠŸ
è®¾è®¡schemaåšåˆ†æ
SQLåªå†™äº†ä¸€é“ï¼Œé€‰å‡ºæ‰€æœ‰åªä¸Šä¼ è¿‡ç…§ç‰‡çš„ç”¨æˆ·
Ownership
çº¯BQï¼ŒèŠå¤©
è‡ªå·±è§‰å¾—é¢å¾—ä¸å¥½æ˜¯å› ä¸ºç¬¬äºŒè½®ETLçš„æ—¶å€™ä¿¡å·ä¸å¥½å¬ä¸æ¸…ï¼Œä¸€ç›´åœ¨é‡å¤é—®é¢˜ï¼Œæ„Ÿè§‰å¯¹æ–¹æœ‰ç‚¹ä¸è€çƒ¦ï¼Œå¼„å¾—æˆ‘ä¹Ÿå¾ˆç´§å¼ ï¼Œproduct senseç­”å¾—ä¹±ä¸ƒå…«ç³Ÿã€‚è€Œä¸”data modelå‰é¢è¯´å¾—å¤ªå¤šå¯¼è‡´æœ€åæ²¡æ—¶é—´åªåšäº†ä¸€é“SQLé¢˜ï¼Œè®¾è®¡çš„schemaä¹Ÿæ²¡æœ‰å®Œå…¨è§£å†³é—®é¢˜ï¼Œä¸€ç›´è¢«è¿½é—®ç»†èŠ‚ï¼Œå†…å¿ƒå¾ˆå´©æºƒã€‚
ä¸è¿‡ä»ç»“æœæ¥çœ‹ä¼¼ä¹ä¹Ÿæ²¡æœ‰æˆ‘è‡ªå·±æƒ³è±¡çš„é‚£ä¹ˆç³Ÿç³•ã€‚æˆ‘çš„ç»éªŒå°±æ˜¯ä¸ä¼šä¸è¦ç´§å¼ ï¼Œè¦ä¸€ç›´è¯´è‡ªå·±çš„æƒ³æ³•ï¼Œdata modelé‚£ä¸€è½®æˆ‘è¢«é—®åˆ°ç­”ä¸ä¸Šæ¥çš„æ—¶å€™å°±ä¼šè¯´è™½ç„¶æˆ‘ä¸çŸ¥é“èƒ½ä¸èƒ½è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æˆ‘æƒ³åˆ°çš„æ–¹æ¡ˆæœ‰1ï¼Œ2ï¼Œ3ï¼Œè‚¯å®šæ¯”ç›´æ¥å†·åœºè¦å¥½ä¸€äº›ã€‚

[structured study guide](https://www.notion.so/structured-study-guide-1cfeec220fb58057b3f6f4c1c5e07633?pvs=21)

[HR Interview questions](https://www.notion.so/HR-Interview-questions-1d1eec220fb5805cb680f01d92230052?pvs=21)

[7 day challenge](https://www.notion.so/7-day-challenge-1d3eec220fb58060b008edba6d44528f?pvs=21)

[Playground](https://www.notion.so/Playground-1d3eec220fb5809a8f4ee71b5fd14e85?pvs=21)

---

---

---

---

carpoolï¼š

SQLï¼š
percentage
(drivers(distinct) who take carpool more than regularly )/ total drivers

Python:
if more than capacity (default 6) return False

Newsfeed(reels):

PS:
How to track if a user moves from their regular location to a new location?
Compare the likes of original content and the likes of content that is shared from the original.

DM:
Visualization: show how the reelsâ€™ launching affects other functions (posts, pictures and long videos)

SQL:
(Content created today, which has type â€œreactionâ€ but no â€œcommentâ€)/total content created today

Pythonï¼šç”¨ï¼ˆdequeï¼‰
Use buffer store element (default =3), if test then add to buffer but not aggregation and print
left(oldest) out ,right(new) in
aggregation: 1. total engagement, 2. total views ( ms/1000 to s)
post_id use â€œ, â€.join to string

streamingï¼ˆNetflixï¼‰:

SQLï¼š
Use outer join + coalesce to merge todayâ€™s snapshot with the current table, aggregating total view time.
(è¦æ±‚ï¼š1. ä¸è¦scanå…¨è¡¨ï¼Œ2.ç”¨select syntaxï¼‰
gourd byï¼Œ ç»™äº†ä¸¤ä¸ªè¡¨å’Œæ•°æ®ï¼Œä¸€ä¸ªæ˜¯watch_factï¼Œä¸€ä¸ªæ˜¯session_dim,ã€‚åªç”¨åˆ°factè¡¨ï¼Œgroup by content_id count(distinct user),sum(total time)

Python:
æ¯ä¸ªç”µå½±çš„å¹³å‡rating.

---

---

---

æœ¬å¸–æœ€åç”± andy3545 äº 2025-2-13 12:23 ç¼–è¾‘

Onsite Interviews:

Very similar to this post.

Behavioral Round (Indian Interviewer)
Interviewed by an Indian manager, very friendly.
Be prepared for follow-up questionsâ€”they ask follow up questions if your answer does not give signals they're looking for. Check out this blog for different signals.
What does data engineering mean to you?
Using data to make an impact or convince others
Leading projects and their impact
How do you plan to succeed at Meta?
Prioritizing competing tasksâ€”any frameworks/tools?
A time when you were wrongâ€”how did you handle it?

Full Stack 1 (Chinese Interviewer):
Scenario: Video Streaming Platform (like Netflix), focused on user engagement.
SQL (2 Questions): Update a daily aggregate table from a user activity fact table.
Python (2 Questions): Given a list of movies and categories, map movies to categories and return top 3 movies per category.

Full Stack 2 (Mexican Interviewer)
Scenario: Ride-sharing company introducing a carpooling feature.
Discuss value proposition and Metaâ€™s mission alignment.
Data Modeling: Support rides with multiple riders (IMPORTANT!)
SQL (3 Questions): Very easy.
Python (1 Question): Similar to Leetcodeâ€™s Meeting Rooms questionâ€”determine if all rides can be completed.
Bonus ML Question: Finished early, so I got a machine learning question, which I solved.

Full Stack 3 (Indian Interviewer)
Scenario: Facebook adding short-form videos (Reels).
Data Modeling: Handle posts shared 10,000+ times (Hint: Use an array to store shares).
SQL (2 Questions): Identify posts with zero likes/reacts on the day they were posted.
Python (1 Question): Process a stream of input data (list of dictionaries), checking conditions, buffering output, and handling edge cases.

Key Takeaways

Questions are straightforward, but speed is criticalâ€”you canâ€™t afford to get stuck.
Interviewers help you succeedâ€”they give hints if needed, but explain your thought process.
Receiving hints isnâ€™t badâ€”responding to them well shows learnings abilities, a key hiring signal.
Utilize the information your recruiter providesâ€”they often share valuable information and even similar questions that may appear in the interview.
Data Modeling â€“ Since we're assuming a dataset with billions of records, bonus points for discussing data partitioning strategies and optimizing dashboards by reading from a daily aggregated table instead of the raw fact table.

Best of Luck. åŠ æ²¹!!

è¡¥å……å†…å®¹ (2025-02-14 22:25 +08:00):

Data Modeling: Handle posts shared 10,000+ times (Hint: Use an array to store shares).

Standard newsfeed data model, but the follow up question was "How does your data model handle multiple layers of sharing, and efficietly count how many shares each post has and who the original poster and posted time is?"

For example:
user_1 shares, then user_2 sees user_1's post and shares, this is considered 2 layers of sharing.
Imaginge there is 1000+ layers

---

---

â€”

è„¸ä¹¦DATA ENGINEER é¢ç»åŠæ€»ç»“ [ğŸ”—Â www.1point3acres.com](https://www.1point3acres.com/bbs/thread-601367-1-1.html)
ä¹°å®ƒonsite data eng å›æŠ¥ç¤¾ä¼šÂ Â [ğŸ”—Â www.1point3acres.com](https://www.1point3acres.com/bbs/thread-850462-1-1.html)
Meta DE Phone + Onsite é¢ç» - OrzÂ Â [ğŸ”—Â www.1point3acres.com](https://www.1point3acres.com/bbs/thread-817312-1-1.html)
FB DE ç”µé¢ VOÂ Â [ğŸ”—Â www.1point3acres.com](https://www.1point3acres.com/bbs/thread-629763-1-1.html)

VOè¿˜æ˜¯å¯ä»¥å‚è€ƒä¸Šé¢å¸–å­ä¸­çš„é¢˜ç›®ï¼Œé¢è¯•æ—¶å¯èƒ½ä¼šå‡ºç°ä¸åŒçš„Use Caseå’Œfeatureã€‚ä¸‹é¢æˆ‘åˆ†äº«æˆ‘é‡åˆ°çš„é¢˜ç›®å’Œåœºæ™¯ã€‚

ç¬¬ä¸€è½®ï¼š Ride Sharing Companyã€‚æœ€è¿‘åŠ äº†ä¸€ä¸ªCarpoolçš„åŠŸèƒ½ï¼Œå¦‚æœåˆ¤æ–­æˆåŠŸä¸å¦ï¼Œéœ€è¦å“ªäº›Metricsï¼Œ data modeling designï¼Œç„¶å SQL + Pythonã€‚ SQL é¢˜ç›®å·²ç»å¿˜äº†ï¼Œåªè®°å¾—ä¸€é“é¢˜ç›®ç”¨åˆ°äº† sub-queryã€‚
Python é¢˜ç›®ï¼šinput æ˜¯ a list of bookingsï¼ˆdictionaryï¼‰ã€‚åˆ¤æ–­æ˜¯å¦æ‰€æœ‰è®¢å•å¯ä»¥é€šè¿‡Carpoolå®Œæˆã€‚

ç¬¬äºŒè½®ï¼š Video Streaming Company ï¼ˆlike Netflixï¼‰ã€‚ SQL è€ƒäº† batch processingã€‚å°±æ˜¯å¦‚ä½•updateï¼Œ æˆ‘æœ€åç”¨çš„Mergeã€‚Pythoné¢˜ç›®å¿˜è®°äº†ï¼Œåªè®°å¾—ç”¨äº† nested loop + if check conditionsã€‚
å¯èƒ½è¿™ä¸€è½®å¤ªé¡ºäº†ï¼Œæ²¡ç•™ä¸‹å¤ªå¤šå°è±¡ã€‚é¢è¯•å®˜ä¹Ÿå¾ˆç»™åŠ›ï¼Œäº¤æµå¾ˆé¡ºåˆ©ã€‚

ç¬¬ä¸‰è½®ï¼š Newsfeedã€‚ æœ€è¿‘åŠ äº†ä¸€ä¸ªshort Videoçš„åŠŸèƒ½ï¼Œåˆ¤æ–­è¿™ä¸ªåŠŸèƒ½å¯¹newsfeedçš„å½±å“ã€‚å¥—è·¯ä¸€æ ·ï¼Œè¿˜æ˜¯éœ€è¦å“ªäº›Metricsï¼Œ data modeling designï¼Œè¿˜é—®dashboard å¦‚ä½•è®¾è®¡ã€‚
è¿™ä¸€è½®æˆ‘é¢çš„çœŸæ˜¯ä¹±ä¸ƒå…«ç³Ÿã€‚SQLé¢˜ç›®å¿˜è®°äº†ï¼Œåªè®°ç”¨åˆ° Count - Count ï¼ˆreverse thinkingï¼‰ï¼Œå°±è¿™é¢è¯•å®˜æ„£æ˜¯ä¸æ˜ç™½ï¼ŒèŠ±äº†10åˆ†é’Ÿè§£é‡Šï¼Œæœ€åè¯´ä½ å¥½åƒåšçš„å¯¹çš„ã€‚

Pythonå¾ˆæœ‰æ„æ€ï¼Œå¤§æ¦‚æ˜¯è¿™æ ·çš„

Write a python function to take an input of stream data (list of dictionaries) and then print it out following some string format.

Inside the function, You need to create a buffer with certain size to take the input before print ,which means the print only gets executed after buffer is full and then repeat the process to print out all the steam data.

æœ€åç¥å¤§å®¶é¢è¯•é¡ºåˆ©ï¼ŒMetaç»™çš„å‡†å¤‡æ—¶é—´æˆ‘è§‰å¾—æ˜¯å¤Ÿçš„ï¼ŒæŠŠé¢ç»å’ŒåŸºç¡€å¼„ç†Ÿï¼Œç›¸ä¿¡è‡ªå·±ï¼Œå†·é™ä¸“æ³¨ï¼Œä½ å®šä¼šæ‰‹èµ·åˆ€è½ï¼ŒåŠ›æ–©Offerã€‚

---

---

ä»æ¥åˆ°recruiteråé¦ˆåˆ°ç°åœ¨ä¸¤å‘¨ï¼Œæ€»ç®—æ•´ç†å¥½å¿ƒæƒ…æ¥ä¸€æ³¢æŒ‚ç»
å…ˆæ±‚ä¸ªç±³ï¼Œéœ€è¦å®‰æ…°
æ„Ÿè°¢ï¼š
å¸®åŠ©è¿‡æˆ‘çš„æœ‹å‹ä»¬ï¼Œç‰¹åˆ«ç‰¹åˆ«æ˜¯é‚£ä½å·²ç»é¡ºåˆ©æ‹¿åˆ°offerçš„å¤§ä½¬ï¼Œä¸ä»…æ— ç§çš„åˆ†äº«ç»éªŒï¼Œè¿˜å…¨ç¨‹é™ªæˆ‘èµ°å®Œé¢è¯•æµç¨‹ï¼Œå¯æƒœå¾ˆé—æ†¾æ²¡èƒ½ä¸€èµ·åŠ å…¥metaåšæˆ˜å‹ã€‚
å»ºè®®ï¼š
å¦‚æœé¢è¯•å®˜ç¡®å®šæ˜¯å°ï¼Œèƒ½é¿å¼€å°±é¿å¼€ï¼Œåƒä¸‡åˆ«å­¦æˆ‘å¤´é“ï¼Œè¿ä¸­3å…ƒã€‚
è¿Ÿåˆ°ï¼Œæ‹–æ—¶é—´ã€‚
DMé¢è¯•æ—¶å„ç§é—®é¢˜ï¼Œä¹Ÿç»™æ­£åé¦ˆï¼Œç„¶åhcæ—¶ç»™å·®è¯„
SQLåªå‡ºä¸€é¢˜å°±è·³åˆ°pythonå»ï¼Œåæ‰‹sqlå·®è¯„ã€‚
Pythonä¸è¯»å®Œé¢˜ä¸è®©ä½ å¼€å§‹åšç­‰
ä»¥ä¸‹é¢ç»
é¢˜è¿˜æ˜¯è€é¢˜,æœ‰å›å¿†èµ·æ–°çš„ä¼šæ¥æ·»åŠ 

carpoolï¼š

SQLï¼š
percentage
(drivers(distinct) who take carpool more than regularly )/ total drivers

Python:
if more than capacity (default 6) return False

Newsfeed(reels):

PS:
How to track if a user moves from their regular location to a new location?
Compare the likes of original content and the likes of content that is shared from the original.

DM:
Visualization: show how the reelsâ€™ launching affects other functions (posts, pictures and long videos)

SQL:
(Content created today, which has type â€œreactionâ€ but no â€œcommentâ€)/total content created today

Pythonï¼šç”¨ï¼ˆdequeï¼‰
Use buffer store element (default =3), if test then add to buffer but not aggregation and print
left(oldest) out ,right(new) in
aggregation: 1. total engagement, 2. total views ( ms/1000 to s)
post_id use â€œ, â€.join to string

streamingï¼ˆNetflixï¼‰:

SQLï¼š
Use outer join + coalesce to merge todayâ€™s snapshot with the current table, aggregating total view time.
(è¦æ±‚ï¼š1. ä¸è¦scanå…¨è¡¨ï¼Œ2.ç”¨select syntaxï¼‰
gourd byï¼Œ ç»™äº†ä¸¤ä¸ªè¡¨å’Œæ•°æ®ï¼Œä¸€ä¸ªæ˜¯watch_factï¼Œä¸€ä¸ªæ˜¯session_dim,ã€‚åªç”¨åˆ°factè¡¨ï¼Œgroup by content_id count(distinct user),sum(total time)

Python:
æ¯ä¸ªç”µå½±çš„å¹³å‡rating.

comp -

E4

16w

15% perf bonus

14w rsu 4 years

---

---

Bay area E4

188000

15% year end bonus

273000 RSU

sign on bonus 30k 

---

|  | **Level NameTag** | **Years of ExperienceTotal / At Company** | **Total CompensationÂ (USD)Base | StockÂ (yr)Â | Bonus** |
| --- | --- | --- | --- |
|  | **IC4**Data | **5Â yrs**0Â yrs | [**+$27K**](https://www.levels.fyi/services/?from=compensation_table)
**$262,100**179KÂ |Â 51.3KÂ |Â 31.9K |

[Key concepts](https://www.notion.so/Key-concepts-1e3eec220fb5805c975bf6413202bb19?pvs=21)

[GPT Study Guide](https://www.notion.so/GPT-Study-Guide-1e5eec220fb580f2bd0cef96d97f9594?pvs=21)

[Product Sense, SQL & Behavioral Interview Prep (Reformatted)](https://www.notion.so/Product-Sense-SQL-Behavioral-Interview-Prep-Reformatted-1eaeec220fb58000bc78f997e144c83c?pvs=21)

[Product & SQL Interview Prep Solutions.wav](attachment:8a8ee3ae-ce03-4d25-af39-f01896fff011:Product__SQL_Interview_Prep_Solutions.wav)

[Behavioral Interview 1](https://www.notion.so/Behavioral-Interview-1-1eeeec220fb580d0a941c1c59a143c26?pvs=21)

[Behavioral Interview - Product Minded](https://www.notion.so/Behavioral-Interview-Product-Minded-1eeeec220fb58083b4d0e11b5c3639ed?pvs=21)

based on the latest version of document - generate a challenge document named 5-15-Carpool Challenge for me on the carpool-doordash questions in the same format with all the answers at the end including sql and python scripts - make sure to base your questions and answers on the existing contents of the document and the additional contents that I provided here: carpoolï¼š

[Meta Data Engineering Guideline Summary](https://www.notion.so/Meta-Data-Engineering-Guideline-Summary-1f5eec220fb580848907c5224ca166c1?pvs=21)